# Reproducibility
seed: 0

# WandB
wandb:
  wandb_run_id: null
  wandb_run_name: fold_0_freeze_enc
  wandb_project_name: GenesisFinetuneTest
  # logs_path: /home/gridsan/nchutisilp/datasets/ModelGenesisOutputs/ModelGenesisNNUNetFinetuningV2_noNorm/LogsBCEAugUniform # SuperCloud
  logs_path: logs # Bizon

# Data
data:
  fold: 0 # should change when doing different folds
  # data_directory: /home/gridsan/nchutisilp/datasets/nnUNet_Datasets/nnUNet_raw/Dataset303_Calcium_OCTv2/ # SuperCloud
  data_directory: /storage_bizon/naravich/nnUNet_Datasets/nnUNet_raw/Dataset303_Calcium_OCTv2/ # Bizon
  patch_size: [128, 128, 64]
  queue_max_length: 720 # 180 (patches per volume) x 4 (training volumes)
  samples_per_volume: 180 # (500x500x375) / (128x128x64) ~ 89.4
  num_workers: 39
  batch_size: 16
  num_classes: 1

# Train
train:
  max_epochs: 2000
  patience: 300

# Pre-trained
# pre_trained_weight_path: /home/gridsan/nchutisilp/datasets/ModelGenesisOutputs/ModelGenesisNNUNetPretrainingV2_noNorm/Genesis_OCT_Best.pt # SuperCloud
pre_trained_weight_path: null
# pre_trained_weight_path: /storage_bizon/naravich/ModelGenesisNNUNetPretrainingV2_noNorm/Genesis_OCT_Best.pt # Bizon

# Model
model:
  freeze_encoder: True
  head:
    task: regression
    in_channels: 320
    pooling: avg
    dropout: 0.2


# Optimizer
optimizer:
  learning_rate: 2
  momentum: 0.9
  weight_decay: 0.0
  nesterov: False
  scheduler_step_size: 60
  scheduler_gamma: 0.5

# nnUNet architecutre
nnUNet:
  dataset_name_or_id: "301"
  configuration: 3d_fullres
  trainer_name: nnUNetTrainer
  plans_identifier: nnUNetPlans
  fold: 0 # any fold would do