{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to explore the encoded vector of the nnUNet to create an decoder to regress / classify the output instead of segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "print(os.getcwd().split('/')[-1])\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    sys.path.append('../pytorch')\n",
    "    print('Added path to sys')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the nnUNet model\n",
    "from utils import KFoldNNUNetSegmentationDataModule, GenesisSegmentation\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "# Load the config file\n",
    "config = yaml.load(open('../pytorch/configs/fine_tune_config-regression.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "# Model\n",
    "model = GenesisSegmentation(config=config).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the encoder\n",
    "encoder = model.model.encoder \n",
    "\n",
    "input_sample = torch.randn(1, 1, *config['data']['patch_size'])\n",
    "output_sample = encoder(input_sample)\n",
    "[feat.shape for feat in output_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to know if the Whole-Volumetric-OCT-Image can be cropped to a smaller size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def get_positive_bounds(image):\n",
    "    image = sitk.GetArrayFromImage(image)\n",
    "    zs, xs, ys = np.where(image > 0)\n",
    "    for z, x, y in zip(zs, xs, ys):\n",
    "        assert image[z, x, y] > 0\n",
    "\n",
    "    return zs.min(), zs.max(), xs.min(), xs.max(), ys.min(), ys.max()\n",
    "\n",
    "max_z = -1\n",
    "min_z = 1000\n",
    "max_x = -1\n",
    "min_x = 1000\n",
    "max_y = -1\n",
    "min_y = 1000\n",
    "\n",
    "min_img_z, max_img_z, min_img_x, max_img_x, min_img_y, max_img_y = 1000, -1, 1000, -1, 1000, -1\n",
    "\n",
    "data_dir = Path('/storage_bizon/naravich/nnUNet_Datasets/nnUNet_raw/Dataset303_Calcium_OCTv2/imagesTr/').glob('*.nii.gz')\n",
    "label_dir = Path('/storage_bizon/naravich/nnUNet_Datasets/nnUNet_raw/Dataset303_Calcium_OCTv2/labelsTr/').glob('*.nii.gz')\n",
    "print('train')\n",
    "for file in data_dir:\n",
    "    img = sitk.ReadImage(str(file))\n",
    "    print(img.GetSize(), file.stem)\n",
    "    positive_bounds = get_positive_bounds(img)\n",
    "    min_img_z = min(min_img_z, positive_bounds[0])\n",
    "    max_img_z = max(max_img_z, positive_bounds[1])\n",
    "    min_img_x = min(min_img_x, positive_bounds[2])\n",
    "    max_img_x = max(max_img_x, positive_bounds[3])\n",
    "    min_img_y = min(min_img_y, positive_bounds[4])\n",
    "    max_img_y = max(max_img_y, positive_bounds[5])\n",
    "\n",
    "print('label')\n",
    "for file in label_dir:\n",
    "    img = sitk.ReadImage(str(file))\n",
    "    print(img.GetSize(), file.stem)\n",
    "    positive_bounds = get_positive_bounds(img)\n",
    "    min_z = min(min_z, positive_bounds[0])\n",
    "    max_z = max(max_z, positive_bounds[1])\n",
    "    min_x = min(min_x, positive_bounds[2])\n",
    "    max_x = max(max_x, positive_bounds[3])\n",
    "    min_y = min(min_y, positive_bounds[4])\n",
    "    max_y = max(max_y, positive_bounds[5])\n",
    "\n",
    "data_dir = Path('/storage_bizon/naravich/nnUNet_Datasets/nnUNet_raw/Dataset303_Calcium_OCTv2/imagesTs/').glob('*.nii.gz')\n",
    "label_dir = Path('/storage_bizon/naravich/nnUNet_Datasets/nnUNet_raw/Dataset303_Calcium_OCTv2/labelsTs/').glob('*.nii.gz')\n",
    "print('test')\n",
    "for file in data_dir:\n",
    "    img = sitk.ReadImage(str(file))\n",
    "    print(img.GetSize(), file.stem)\n",
    "    positive_bounds = get_positive_bounds(img)\n",
    "    min_img_z = min(min_img_z, positive_bounds[0])\n",
    "    max_img_z = max(max_img_z, positive_bounds[1])\n",
    "    min_img_x = min(min_img_x, positive_bounds[2])\n",
    "    max_img_x = max(max_img_x, positive_bounds[3])\n",
    "    min_img_y = min(min_img_y, positive_bounds[4])\n",
    "    max_img_y = max(max_img_y, positive_bounds[5])\n",
    "\n",
    "for file in label_dir:\n",
    "    img = sitk.ReadImage(str(file))\n",
    "    print(img.GetSize(), file.stem)\n",
    "    positive_bounds = get_positive_bounds(img)\n",
    "    min_z = min(min_z, positive_bounds[0])\n",
    "    max_z = max(max_z, positive_bounds[1])\n",
    "    min_x = min(min_x, positive_bounds[2])\n",
    "    max_x = max(max_x, positive_bounds[3])\n",
    "    min_y = min(min_y, positive_bounds[4])\n",
    "    max_y = max(max_y, positive_bounds[5])\n",
    "\n",
    "print('Minimum croppable bound is: ')\n",
    "print(min_z, max_z, min_x, max_x, min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the image data, the image is 3D and the size cannot be cropped to a smaller size. As for the label, it can be cropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the UNetRegressor\n",
    "class UNetRegressor(torch.nn.Module):\n",
    "    def __init__(self, n_classes: int, task: str = 'regression'):\n",
    "        super(UNetRegressor, self).__init__()\n",
    "        self.encoder = model.model.encoder\n",
    "        \"\"\"\n",
    "        >>> input_sample = torch.randn(1, 1, 512, 512, 384)\n",
    "        >>> output_sample = encoder(input_sample)\n",
    "        >>> [feat.shape for feat in output_sample]\n",
    "        >>> [torch.Size([1, 32, 512, 512, 384]),\n",
    "             torch.Size([1, 64, 256, 256, 192]),\n",
    "             torch.Size([1, 128, 128, 128, 96]),\n",
    "             torch.Size([1, 256, 64, 64, 48]),\n",
    "             torch.Size([1, 320, 32, 32, 24]),\n",
    "             torch.Size([1, 320, 32, 16, 12])]\n",
    "        \"\"\"\n",
    "        # self.decoder = model.model.decoder\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(320, 320, kernel_size=(32, 16, 12), stride=1, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv3d(320, 160, kernel_size=1, stride=1, bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv3d(160, n_classes, kernel_size=1, stride=1, bias=True),\n",
    "        )\n",
    "        self.last_activation = torch.nn.Sigmoid() if task == 'regression' else torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[-1]\n",
    "        x = self.regressor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the UNetRegressor\n",
    "class UNetRegressorHead(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, n_classes: int, pooling=\"avg\", dropout=0.2, task: str = 'regression'):\n",
    "        super(UNetRegressorHead, self).__init__()\n",
    "        \"\"\"\n",
    "        >>> input_sample = torch.randn(1, 1, 512, 512, 384)\n",
    "        >>> output_sample = encoder(input_sample)\n",
    "        >>> [feat.shape for feat in output_sample]\n",
    "        >>> [torch.Size([1, 32, 512, 512, 384]),\n",
    "             torch.Size([1, 64, 256, 256, 192]),\n",
    "             torch.Size([1, 128, 128, 128, 96]),\n",
    "             torch.Size([1, 256, 64, 64, 48]),\n",
    "             torch.Size([1, 320, 32, 32, 24]),\n",
    "             torch.Size([1, 320, 32, 16, 12])]\n",
    "        \"\"\"\n",
    "        if pooling not in (\"max\", \"avg\"):\n",
    "            raise ValueError(\"Pooling should be one of ('max', 'avg'), got {}.\".format(pooling))\n",
    "\n",
    "        if task not in (\"regression\", \"classification\"):\n",
    "            raise ValueError(\"Task should be one of ('regression', 'classification'), got {}.\".format(task))\n",
    "\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.AdaptiveAvgPool3d(1) if pooling == \"avg\" else torch.nn.AdaptiveMaxPool3d(1),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Dropout(p=dropout, inplace=True) if dropout > 0 else torch.nn.Identity(),\n",
    "            torch.nn.Linear(in_channels, n_classes, bias=True),\n",
    "            torch.nn.ReLU() if task == 'regression' else torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.regressor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.model.encoder\n",
    "input_sample = torch.randn(10, 1, *config['data']['patch_size'])\n",
    "output_sample = encoder(input_sample)\n",
    "regressor = UNetRegressorHead(in_channels=320, n_classes=2, pooling=\"avg\", dropout=0.2, task='classification')\n",
    "output_sample = regressor(output_sample[-1])\n",
    "output_sample.shape, output_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.GetPixel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
